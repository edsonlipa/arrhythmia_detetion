{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys, os\n",
    "import wfdb\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pk\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score \n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_names = ['100', '101', '102', '103', '104', '105', '106', '107', \n",
    "              '108', '109', '111', '112', '113', '114', '115', '116', \n",
    "              '117', '118', '119', '121', '122', '123', '124', '200', \n",
    "              '201', '202', '203', '205', '207', '208', '209', '210', \n",
    "              '212', '213', '214', '215', '217', '219', '220', '221', \n",
    "              '222', '223', '228', '230', '231', '232', '233', '234']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tamnoho de las ventanas derecha e izquierdas\n",
    "widb = 99\n",
    "wida = 160\n",
    "n_samples = 650000 #<650000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['N', 'S', 'V', 'F', 'Q']\n",
    "sub_labels = ['N', 'L', 'R', 'e', 'j', 'A', 'a', 'J', 'S', 'V', 'E', 'F', '/', 'f', 'Q']\n",
    "sub = {'N':'N', 'L':'N', 'R':'N', 'e':'N', 'j':'N', \n",
    "       'A':'S', 'a':'S', 'J':'S', 'S':'S',\n",
    "       'V':'V', 'E':'V',\n",
    "       'F':'F',\n",
    "       '/':'Q', 'f':'Q', 'Q':'Q'}\n",
    "X = []\n",
    "Y = []\n",
    "for d in data_names:\n",
    "    r=wfdb.rdrecord('./data/'+d)\n",
    "    ann=wfdb.rdann('./data/'+d, 'atr', return_label_elements=['label_store', 'symbol'])\n",
    "    if d!='114':\n",
    "        sig = np.array(r.p_signal[:,0])\n",
    "    else:\n",
    "        sig = np.array(r.p_signal[:,1])\n",
    "    sig_len = len(sig)\n",
    "    sym = ann.symbol\n",
    "    pos = ann.sample\n",
    "    beat_len = len(sym)\n",
    "    for i in range(beat_len):\n",
    "        if sym[i] in labels and pos[i]-widb>=0 and pos[i]+wida+1<=sig_len:\n",
    "            a = sig[pos[i]-widb:pos[i]+wida+1]\n",
    "            if len(a) != 260:\n",
    "                print(\"Length error\")\n",
    "                continue\n",
    "            X.append(a)\n",
    "            Y.append(labels.index(sub[sym[i]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82986, 260)\n",
      "(82986,)\n",
      "Counter({0: 75020, 2: 7129, 3: 802, 4: 33, 1: 2})\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "count = Counter(Y)\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_ = 200 #se puede cambiar para variar los datos y reproducir los resultados\n",
    "data_len = len(X)\n",
    "np.random.seed(seed_)\n",
    "idx = list(range(data_len))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(idx)\n",
    "\n",
    "train_len = int(data_len*0.6) # 60%\n",
    "valid_len = int(data_len*0.2) # 20%\n",
    "test_len = data_len-train_len-valid_len # 20%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49791, 260)\n",
      "(16597, 260)\n",
      "(16598, 260)\n",
      "Counter({0: 44982, 2: 4298, 3: 490, 4: 20, 1: 1})\n",
      "Counter({0: 15027, 2: 1395, 3: 167, 4: 8})\n",
      "Counter({0: 15011, 2: 1436, 3: 145, 4: 5, 1: 1})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = X[idx][:train_len]\n",
    "X_valid = X[idx][train_len:train_len+valid_len]\n",
    "X_test = X[idx][train_len+valid_len:]\n",
    "Y_train = Y[idx][:train_len]\n",
    "Y_valid = Y[idx][train_len:train_len+valid_len]\n",
    "Y_test = Y[idx][train_len+valid_len:]\n",
    "\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)\n",
    "print(Counter(Y_train))\n",
    "print(Counter(Y_valid))\n",
    "print(Counter(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49791, 260, 1)\n",
      "(16597, 260, 1)\n",
      "(16598, 260, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_valid = np.expand_dims(X_valid, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 2 ... 0 0 0]\n",
      "(49791, 5)\n"
     ]
    }
   ],
   "source": [
    "f_size = X_train.shape[1]\n",
    "class_num = 5\n",
    "\n",
    "lr = 0.01\n",
    "batch_size=32\n",
    "\n",
    "print(Y_train)\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes=class_num)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(model_type):\n",
    "    model = Sequential()\n",
    "    if model_type == '1D':\n",
    "        model.add(Conv1D(10, 3, activation='relu', input_shape=(f_size,1)))\n",
    "        model.add(MaxPooling1D(2))\n",
    "        model.add(Conv1D(10, 3, activation='relu'))\n",
    "        model.add(MaxPooling1D(2))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(100, activation='relu'))\n",
    "    elif model_type == '1D-large':\n",
    "        model.add(Conv1D(50, 13, activation='relu', input_shape=(f_size,1)))\n",
    "        model.add(MaxPooling1D(2))\n",
    "        model.add(Conv1D(50, 13, activation='relu'))\n",
    "        model.add(MaxPooling1D(2))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(100, activation='relu'))\n",
    "    elif model_type == 'LSTM':\n",
    "        model.add(LSTM(64, return_sequences=True, dropout=0.1, input_shape=(f_size, 1)))\n",
    "        model.add(LSTM(32, return_sequences=True, dropout=0.1))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "    elif model_type == 'BiLSTM':\n",
    "        model.add(Bidirectional(LSTM(64, return_sequences=True, dropout=0.1), merge_mode='sum', input_shape=(f_size, 1)))\n",
    "        model.add(Bidirectional(LSTM(32, return_sequences=True, dropout=0.1), merge_mode='sum'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "    elif model_type == 'ConvLSTM':\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(10, 7, activation='relu', input_shape=(260,1)))\n",
    "        model.add(MaxPooling1D(3))\n",
    "        model.add(Conv1D(10 ,7, activation='relu'))\n",
    "        model.add(MaxPooling1D(3))\n",
    "        model.add(LSTM(32, return_sequences=True,recurrent_dropout=0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "    model.add(Dense(class_num, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=lr), metrics=['accuracy'])\n",
    "    return model\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 260, 64)           16896     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 260, 32)           12416     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               1065088   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,095,045\n",
      "Trainable params: 1,095,045\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = make_model('LSTM')\n",
    "#model = make_model_cnn_lstm()\n",
    "best_SE = 0\n",
    "best_ACC = 0\n",
    "patience = 30\n",
    "pcnt = 0\n",
    "\n",
    "best_model = make_model('LSTM')\n",
    "\n",
    "bin_label = lambda x: min(1,x)\n",
    "#model.build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | SE: 0.9369 | Best SE: 0.9369 | ACC: 0.9820 | Best ACC: 0.9820 | AUC: 0.9645 | SP: 0.9921\n",
      "Epoch: 2 | SE: 0.9146 | Best SE: 0.9369 | ACC: 0.9886 | Best ACC: 0.9820 | AUC: 0.9565 | SP: 0.9984\n",
      "Epoch: 3 | SE: 0.9153 | Best SE: 0.9369 | ACC: 0.9889 | Best ACC: 0.9820 | AUC: 0.9569 | SP: 0.9986\n",
      "Epoch: 4 | SE: 0.9013 | Best SE: 0.9369 | ACC: 0.9881 | Best ACC: 0.9820 | AUC: 0.9501 | SP: 0.9990\n",
      "Epoch: 5 | SE: 0.9185 | Best SE: 0.9369 | ACC: 0.9892 | Best ACC: 0.9820 | AUC: 0.9584 | SP: 0.9983\n",
      "Epoch: 6 | SE: 0.9102 | Best SE: 0.9369 | ACC: 0.9895 | Best ACC: 0.9820 | AUC: 0.9547 | SP: 0.9993\n"
     ]
    }
   ],
   "source": [
    "save = 'best_train'\n",
    "for e in range(1, 300+1):\n",
    "\n",
    "    model.fit(X_train, Y_train, batch_size=batch_size, epochs=1, verbose=0)\n",
    "\n",
    "    y_pred = model.predict(X_valid)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    acc = np.sum(y_pred==Y_valid)/len(Y_valid)\n",
    "\n",
    "    y_true = list(map(bin_label, Y_valid))\n",
    "    y_pred = list(map(bin_label, y_pred))\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    SE = tp/(tp+fn)\n",
    "    SP = tn/(fp+tn)\n",
    "\n",
    "    if SE+acc > best_SE+best_ACC:\n",
    "        best_SE, best_ACC = SE, acc\n",
    "        best_model.set_weights(model.get_weights())\n",
    "        pcnt = 0\n",
    "    else:\n",
    "        pcnt += 1\n",
    "    \n",
    "    print(\"Epoch: %d | SE: %.4f | Best SE: %.4f | ACC: %.4f | Best ACC: %.4f | AUC: %.4f | SP: %.4f\" %(e, SE, best_SE, acc, best_ACC, auc, SP))\n",
    "    if pcnt==patience:\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        acc = np.sum(y_pred==Y_test)/len(Y_test)\n",
    "        y_true = list(map(bin_label, Y_test))\n",
    "        y_pred = list(map(bin_label, y_pred))\n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        SE = tp/(tp+fn)\n",
    "        SP = tn/(fp+tn)\n",
    "        print(\"LSTM Test | SE: %.4f | ACC: %.4f | AUC: %.4f | SP: %.4f | valid SE: %.4f | valid ACC: %.4f\" %(SE, acc, auc, SP, best_SE, best_ACC))\n",
    "        with open(\"./result/\"+save, \"a\") as fw:\n",
    "            fw.write(\"SE: %.4f | ACC: %.4f | AUC: %.4f | SP: %.4f | valid SE: %.4f | valid ACC: %.4f\\n\" %(SE, acc, auc, SP, best_SE, best_ACC))\n",
    "        break\n",
    "\n",
    "model.save('LSTM_trained')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
